{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usCvd9-Pv848"
   },
   "source": [
    "#Introduction\n",
    "This python code is for MaskDetectionVideo function of IN3060/INM460 Computer Vision (PRD2 A 2023/24) Coursework.\n",
    "\n",
    "I will use the video from [Taiwan CDC](https://www.cdc.gov.tw/En) on the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYnTItLgb3BU"
   },
   "source": [
    "## Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20741,
     "status": "ok",
     "timestamp": 1713602944718,
     "user": {
      "displayName": "Ling-Yun Huang",
      "userId": "07776248856149240127"
     },
     "user_tz": -60
    },
    "id": "8dB5CjIeqIWz",
    "outputId": "51aead07-140b-4927-a206-540586d5579b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1713602944718,
     "user": {
      "displayName": "Ling-Yun Huang",
      "userId": "07776248856149240127"
     },
     "user_tz": -60
    },
    "id": "EO-B190juFRg",
    "outputId": "e092ec96-dec6-434d-fe6c-063da2f51a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Models', 'Code', 'CW_Dataset', 'Video', 'Test_functions.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'CV2024-CW-230048952-LYHuang'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEUZHrS76MDY"
   },
   "source": [
    "Install the pre-trained model for face detect.\n",
    "\n",
    "*This code is adopted from Lab 8*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83588,
     "status": "ok",
     "timestamp": 1713603028303,
     "user": {
      "displayName": "Ling-Yun Huang",
      "userId": "07776248856149240127"
     },
     "user_tz": -60
    },
    "id": "DZsNk_4J-Pmq",
    "outputId": "e3d96721-3e01-4481-f54b-314ba0cf10a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting facenet-pytorch\n",
      "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.25.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.31.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.17.1+cu121)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2024.2.2)\n",
      "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision->facenet-pytorch) (2.2.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision->facenet-pytorch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision->facenet-pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision->facenet-pytorch) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
     ]
    }
   ],
   "source": [
    "# install pre-trained models of MTCNN for PyTorch\n",
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKCji7bUcCD2"
   },
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i95zcHHNbzws"
   },
   "outputs": [],
   "source": [
    "# for accessing and preprocessing the video dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte, io, color\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# face detector\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# for animation the video\n",
    "from matplotlib import rc\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Images output with rectangle and label\n",
    "from matplotlib import patches\n",
    "\n",
    "# CNNs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnF0SVn3c4_m"
   },
   "source": [
    "# MaskDetectionVideo Function Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNSaHtkOAAIy"
   },
   "source": [
    "## Video dataset loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJj9RYXrmjjr"
   },
   "outputs": [],
   "source": [
    "# Video loaded\n",
    "def video_loaded(video_dir):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_dir)\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    video = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "\n",
    "    fc = 0\n",
    "    ret = True\n",
    "\n",
    "    while fc < frameCount and ret:\n",
    "        ret, video[fc] = cap.read()\n",
    "        video[fc] = cv2.cvtColor(video[fc], cv2.COLOR_BGR2RGB)\n",
    "        fc += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDFMpPW6dIoK"
   },
   "outputs": [],
   "source": [
    "# Define a dictionary to map predicted labels to text\n",
    "label_text = { '0': \"No mask\", '1': \"Mask\", '2': \"Mask incorrect\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MG15zWXJAM03"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLpvH0_FsfGD"
   },
   "outputs": [],
   "source": [
    "## CNNs architecture\n",
    "# CNNs with one layer of conventional layer\n",
    "class CNN_1(nn.Module):\n",
    "    def __init__(self, hidden_size, kernel_size):\n",
    "        super(CNN_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=hidden_size,\n",
    "                               kernel_size=kernel_size, stride=1, padding=int((kernel_size-1)/2))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(hidden_size * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# CNNs with two layers of conventional layers\n",
    "class CNN_2(nn.Module):\n",
    "    def __init__(self, hidden_size, kernel_size):\n",
    "        super(CNN_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=hidden_size,\n",
    "                               kernel_size=kernel_size, stride=1, padding=int((kernel_size-1)/2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_size, out_channels=hidden_size,\n",
    "                               kernel_size=kernel_size, stride=1, padding=int((kernel_size-1)/2))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(hidden_size * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# CNN\n",
    "def CNN_image(classifier, image):\n",
    "    data_means = [0.485, 0.456, 0.406]\n",
    "    data_stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=data_means, std=data_stds)\n",
    "    ])\n",
    "    img_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Predicted the image\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        output = classifier(img_tensor)\n",
    "        _, predicted_label = torch.max(output, 1)\n",
    "        predicted_label = predicted_label.item()  # Convert to Python scalar\n",
    "\n",
    "    label = label_text.get(str(predicted_label), \"Unknown\")\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxM8usXdEM_p"
   },
   "source": [
    "## The face detector function\n",
    "*The MTCNN pre-trained model code are adopted from Lab 8.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Cf2sjitDBAy"
   },
   "outputs": [],
   "source": [
    "def MTCNN_predicted_image(img, ax):\n",
    "\n",
    "    mtcnn = MTCNN(keep_all=True)\n",
    "    faces_MTCNN, _ = mtcnn.detect(img, landmarks=False)\n",
    "\n",
    "    if faces_MTCNN is not None:\n",
    "        for face in faces_MTCNN:\n",
    "            x, y, w, h = face.astype(int)\n",
    "\n",
    "            if w > 0 and h > 0:\n",
    "                face_test = img[y:h, x:w]  # Extract the detected face region from the original image\n",
    "                resized_image = cv2.resize(face_test, (32, 32)) # resize into 32x32\n",
    "                normalized_image = resized_image.astype('float32') / 255.0 # Convert to float and normalize\n",
    "\n",
    "                CNN_classifier = torch.load(os.path.join(GOOGLE_DRIVE_PATH, 'Models/CNN_classifier.pth'))\n",
    "                label = CNN_image(CNN_classifier, normalized_image)\n",
    "\n",
    "                # Add rectangle and predicted label on image\n",
    "                ax.add_patch(patches.Rectangle(xy=(face[0], face[1]), width=face[2]-face[0], height=face[3]-face[1],\n",
    "                                    fill=False, color='r', linewidth=1.5, label=label))\n",
    "                ax.text(face[0], face[1] - 5, label, color='r', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu8eRGuMAUdk"
   },
   "source": [
    "## Animate video with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQ0rCOMSjn5Q"
   },
   "outputs": [],
   "source": [
    "# animate video with prediction label\n",
    "def animate_video(video):\n",
    "    rc('animation', html='jshtml')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    def frame(i):\n",
    "        ax.clear()\n",
    "        ax.axis('off')\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # Apply MTCNN_predictedCNN function to the ith frame\n",
    "        MTCNN_predicted_image(video[i*10+100, :, :, :], ax)\n",
    "\n",
    "        # Plot the frame\n",
    "        plot=ax.imshow(video[i*10+100, :, :, :])\n",
    "        return plot\n",
    "\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, frame, frames=80)\n",
    "    plt.close()\n",
    "\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSI5emgznhVO"
   },
   "source": [
    "# MaskDetectionVideo Function\n",
    "\n",
    "***Note that the \"GOOGLE_DRIVE_PATH\" must the direction of the folder that have all models and dataset***\n",
    "\n",
    "Functions would be copied into py file for test_function reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzJ8_j8Znjuk"
   },
   "outputs": [],
   "source": [
    "def MaskDetectionVideo(path_to_video):\n",
    "\n",
    "    video = video_loaded(path_to_video) # loaded video\n",
    "    anim = animate_video(video) # animate the video with predict label\n",
    "\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iSVsq5inDjz"
   },
   "outputs": [],
   "source": [
    "# define video path\n",
    "video_dir = os.path.join(GOOGLE_DRIVE_PATH, 'Video/Video.mp4')\n",
    "\n",
    "# Load the CNN model\n",
    "CNN_classifier = torch.load(os.path.join(GOOGLE_DRIVE_PATH, 'Models/CNN_classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 398,
     "output_embedded_package_id": "1Bsp7oFDXgA4egFbbWl8xwaE7lSEBtQF6"
    },
    "executionInfo": {
     "elapsed": 44219,
     "status": "ok",
     "timestamp": 1713608238528,
     "user": {
      "displayName": "Ling-Yun Huang",
      "userId": "07776248856149240127"
     },
     "user_tz": -60
    },
    "id": "FLvhXhqWkswH",
    "outputId": "31ec8943-b3be-4506-846a-d0baea7e26b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MaskDetectionVideo(video_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN1L1YybTqf1dBCJbZin0No",
   "mount_file_id": "1eyy3Z7dnL1JLv9v11ntCnsBkRZH-PLma",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
